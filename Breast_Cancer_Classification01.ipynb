{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10564,"sourceType":"datasetVersion","datasetId":7415}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Breast Cancer Dedection Using CNN","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:42:51.666347Z","iopub.execute_input":"2024-08-06T20:42:51.667386Z","iopub.status.idle":"2024-08-06T20:43:04.742009Z","shell.execute_reply.started":"2024-08-06T20:42:51.667352Z","shell.execute_reply":"2024-08-06T20:43:04.741178Z"}}},{"cell_type":"markdown","source":"This notebook how deep learning methods, particularly convolutional neural networks (CNNs), can be leveraged to improve the accuracy of breast cancer diagnosis using histopathological images. By optimizing these techniques, we aim to enable earlier detection and minimize the devastating impact of this disease.\nAccurate and early diagnosis of breast cancer can significantly improve patient outcomes and reduce the physical and mental toll of the disease.\nGlobally, breast cancer claims the lives of 670,000 people annually and affects 2.3 million women, underscoring the urgent need for enhanced diagnostic tools.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import models, layers\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nimport seaborn as sns\nimport os\nimport PIL\nimport pandas as pd\nimport numpy as np\nfrom tensorflow.keras.layers import Rescaling\nimport glob\nimport cv2\n\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D,MaxPooling2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom keras.metrics import binary_crossentropy\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.metrics import confusion_matrix\nfrom tensorflow.keras.regularizers import l2\nimport itertools","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading Data","metadata":{}},{"cell_type":"code","source":"# Create the dataset\ndataset = glob.glob('/kaggle/input/breast-histopathology-images/IDC_regular_ps50_idx5/**/*.png',recursive = True)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:43:04.743854Z","iopub.execute_input":"2024-08-06T20:43:04.744364Z","iopub.status.idle":"2024-08-06T20:47:36.77517Z","shell.execute_reply.started":"2024-08-06T20:43:04.744339Z","shell.execute_reply":"2024-08-06T20:47:36.77432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for img in dataset[:3]:\n    print(img)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:47:36.776282Z","iopub.execute_input":"2024-08-06T20:47:36.776575Z","iopub.status.idle":"2024-08-06T20:47:36.781994Z","shell.execute_reply.started":"2024-08-06T20:47:36.776551Z","shell.execute_reply":"2024-08-06T20:47:36.780997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## The number of images we have\n\nlen(dataset)    ","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:47:36.783453Z","iopub.execute_input":"2024-08-06T20:47:36.783748Z","iopub.status.idle":"2024-08-06T20:47:36.804981Z","shell.execute_reply.started":"2024-08-06T20:47:36.783724Z","shell.execute_reply":"2024-08-06T20:47:36.804119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The number of patients\n# Folder counts show the number of patients\n\nbasepath = \"../input/breast-histopathology-images/IDC_regular_ps50_idx5/\"\nfolder_count = os.listdir(basepath)\nlen(folder_count) ","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:47:36.807351Z","iopub.execute_input":"2024-08-06T20:47:36.807635Z","iopub.status.idle":"2024-08-06T20:47:36.817371Z","shell.execute_reply.started":"2024-08-06T20:47:36.807612Z","shell.execute_reply":"2024-08-06T20:47:36.816562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualization","metadata":{}},{"cell_type":"code","source":"negative_idc = []\npositive_idc = []\n\nfor img in dataset:\n    if img[-5] == '0' :\n        negative_idc.append(img)\n    \n    elif img[-5] == '1' :\n        positive_idc.append(img)\nplt.figure(figsize = (15, 15))\n\nsome_non = np.random.randint(0, len(negative_idc), 18)\nsome_can = np.random.randint(0, len(positive_idc), 18)\n\ns = 0\nfor num in some_non:\n    \n        img = image.load_img((negative_idc[num]), target_size=(100, 100))\n        img = image.img_to_array(img)\n        \n        plt.subplot(6, 6, 2*s+1)\n        plt.axis('off')\n        plt.title('no cancer')\n        plt.imshow(img.astype('uint8'))\n        s += 1\ns = 1\nfor num in some_can:\n    \n        img = image.load_img((positive_idc[num]), target_size=(100, 100))\n        img = image.img_to_array(img)\n        \n        plt.subplot(6, 6, 2*s)\n        plt.axis('off')        \n        plt.title('cancer positive')\n        plt.imshow(img.astype('uint8'))\n        s += 1\n","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:47:36.818386Z","iopub.execute_input":"2024-08-06T20:47:36.81872Z","iopub.status.idle":"2024-08-06T20:47:40.416211Z","shell.execute_reply.started":"2024-08-06T20:47:36.818697Z","shell.execute_reply":"2024-08-06T20:47:40.414843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(len(negative_idc))\nprint(len(positive_idc))","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:47:40.417605Z","iopub.execute_input":"2024-08-06T20:47:40.418311Z","iopub.status.idle":"2024-08-06T20:47:40.423414Z","shell.execute_reply.started":"2024-08-06T20:47:40.418276Z","shell.execute_reply":"2024-08-06T20:47:40.422418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Categories positive idc or negative idc\n\nnum_negative_idc = len(negative_idc)\nnum_positive_idc = len(positive_idc)\n\n\ncategories = ['Negative IDC', 'Positive IDC']\ncounts = [num_negative_idc, num_positive_idc]\n\n# Graph\nfig, ax = plt.subplots(figsize=(7, 5))\nbars = ax.bar(categories, counts, color=['RoyalBlue', 'coral'])\n\n\nfor bar in bars:\n    height = bar.get_height()\n    ax.text(bar.get_x() + bar.get_width() / 2, height, \n            f'{height}', ha='center', va='bottom')\n\nax.set_xlabel('IDC Status')\nax.set_ylabel('Number of Patches')\nax.set_title('Number of Negative and Positive IDC Patches')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:47:40.424601Z","iopub.execute_input":"2024-08-06T20:47:40.424879Z","iopub.status.idle":"2024-08-06T20:47:40.671437Z","shell.execute_reply.started":"2024-08-06T20:47:40.424855Z","shell.execute_reply":"2024-08-06T20:47:40.670486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since the number of negative idc are more than the number of positive idc shows us imbalanced class problem. This needs to be solved before modelling. ","metadata":{}},{"cell_type":"markdown","source":"## Under-Sampling ","metadata":{}},{"cell_type":"code","source":"## Under-Sampling\n## Keeping X and y separate and under-sampling. \n## The number of images are decreased from 277542 to 40057.\n\ntotal = len(negative_idc) + len(positive_idc)\nppos = len(positive_idc)/total\ndesired = 40000\npsamp = desired/total\nprint(total, ppos, desired, psamp)\n\nnon_img_arr = []\ncan_img_arr = []\nnon_y = []\ncan_y = []\n\nfor i,img in enumerate(negative_idc):\n    if (np.random.uniform() < psamp):\n      n_img = cv2.imread(img, cv2.IMREAD_COLOR)\n      n_img = cv2.resize(n_img, (50, 50), interpolation = cv2.INTER_LINEAR)\n      non_img_arr.append(n_img)\n      non_y.append(0)\n\nfor i,img in enumerate(positive_idc):\n    if (np.random.uniform() < psamp):\n      c_img = cv2.imread(img, cv2.IMREAD_COLOR)\n      c_img = cv2.resize(c_img, (50, 50), interpolation = cv2.INTER_LINEAR)\n      can_img_arr.append(c_img)\n      can_y.append(1)\n\nX = np.concatenate((non_img_arr, can_img_arr))\ny = np.concatenate([non_y,can_y])","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:47:40.672743Z","iopub.execute_input":"2024-08-06T20:47:40.6731Z","iopub.status.idle":"2024-08-06T20:52:14.414251Z","shell.execute_reply.started":"2024-08-06T20:47:40.673069Z","shell.execute_reply":"2024-08-06T20:52:14.413357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def describeData(a,b):\n    print('Total number of images: {}'.format(len(a)))\n    print('Number of IDC(-) Images: {}'.format(np.sum(b==0)))\n    print('Number of IDC(+) Images: {}'.format(np.sum(b==1)))\n    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))\ndescribeData(X,y)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:52:14.415591Z","iopub.execute_input":"2024-08-06T20:52:14.416031Z","iopub.status.idle":"2024-08-06T20:52:14.42377Z","shell.execute_reply.started":"2024-08-06T20:52:14.415998Z","shell.execute_reply":"2024-08-06T20:52:14.422742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train-Test Splitting ","metadata":{}},{"cell_type":"code","source":"## Train-Test Splitting \n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3)\n\nfrom tensorflow.keras.utils import to_categorical\nY_train = to_categorical(Y_train, num_classes = 2)\nY_test = to_categorical(Y_test, num_classes = 2)\n\nprint(\"Training Data Shape:\", X_train.shape)\nprint(\"Testing Data Shape:\", X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:52:14.424993Z","iopub.execute_input":"2024-08-06T20:52:14.425256Z","iopub.status.idle":"2024-08-06T20:52:14.546024Z","shell.execute_reply.started":"2024-08-06T20:52:14.425233Z","shell.execute_reply":"2024-08-06T20:52:14.545102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modelling ","metadata":{}},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', patience=5) #Early Stopping\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(50, 50, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D((2, 2)))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.01)))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.01)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(24, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.01)))\nmodel.add(Dense(2, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:52:14.547064Z","iopub.execute_input":"2024-08-06T20:52:14.547331Z","iopub.status.idle":"2024-08-06T20:52:15.520614Z","shell.execute_reply.started":"2024-08-06T20:52:14.547309Z","shell.execute_reply":"2024-08-06T20:52:15.519624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:52:15.521998Z","iopub.execute_input":"2024-08-06T20:52:15.522366Z","iopub.status.idle":"2024-08-06T20:52:15.536398Z","shell.execute_reply.started":"2024-08-06T20:52:15.522332Z","shell.execute_reply":"2024-08-06T20:52:15.535515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:52:15.539917Z","iopub.execute_input":"2024-08-06T20:52:15.540186Z","iopub.status.idle":"2024-08-06T20:52:15.57809Z","shell.execute_reply.started":"2024-08-06T20:52:15.540163Z","shell.execute_reply":"2024-08-06T20:52:15.577236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Training\n\nhistory = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=10, batch_size=35)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:52:15.579297Z","iopub.execute_input":"2024-08-06T20:52:15.579605Z","iopub.status.idle":"2024-08-06T20:53:53.830168Z","shell.execute_reply.started":"2024-08-06T20:52:15.579581Z","shell.execute_reply":"2024-08-06T20:53:53.829205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Evaluation ","metadata":{}},{"cell_type":"code","source":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:53:53.831878Z","iopub.execute_input":"2024-08-06T20:53:53.832329Z","iopub.status.idle":"2024-08-06T20:53:54.355915Z","shell.execute_reply.started":"2024-08-06T20:53:53.832294Z","shell.execute_reply":"2024-08-06T20:53:54.354962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predicted Values\nY_pred = model.predict(X_test)\nY_pred_classes = np.argmax(Y_pred, axis=1)\nY_true = np.argmax(Y_test, axis=1)\n\n# Confusion matrix \nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes)\n\n# Confusion matrix visualization\nf, ax = plt.subplots(figsize=(6, 4))\nsns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap=\"coolwarm\", linecolor=\"gray\", fmt='.1f', ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:53:54.357396Z","iopub.execute_input":"2024-08-06T20:53:54.357694Z","iopub.status.idle":"2024-08-06T20:53:57.995765Z","shell.execute_reply.started":"2024-08-06T20:53:54.357668Z","shell.execute_reply":"2024-08-06T20:53:57.994827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test,Y_test)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:53:57.996921Z","iopub.execute_input":"2024-08-06T20:53:57.997203Z","iopub.status.idle":"2024-08-06T20:54:00.46347Z","shell.execute_reply.started":"2024-08-06T20:53:57.997179Z","shell.execute_reply":"2024-08-06T20:54:00.462569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checking","metadata":{}},{"cell_type":"code","source":"def img_plot(arr,index=0):\n    plt.title('Test Image')\n    plt.imshow(arr[index])\n    \nindex = 1\nimg_plot(X_test, index)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:54:00.464741Z","iopub.execute_input":"2024-08-06T20:54:00.465035Z","iopub.status.idle":"2024-08-06T20:54:00.728489Z","shell.execute_reply.started":"2024-08-06T20:54:00.46501Z","shell.execute_reply":"2024-08-06T20:54:00.727537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def img_plot(arr,index=0):\n    plt.title('Test Image')\n    plt.imshow(arr[index])\nindex = 1\ninput = X_test[index:index+1]\npred = model.predict(input)[0].argmax()\nlabel = Y_test[index].argmax()\nprint('Predicted Value using  cnn model',pred)\nprint(\"True Value\",label)","metadata":{"execution":{"iopub.status.busy":"2024-08-06T20:54:00.730049Z","iopub.execute_input":"2024-08-06T20:54:00.730487Z","iopub.status.idle":"2024-08-06T20:54:01.605716Z","shell.execute_reply.started":"2024-08-06T20:54:00.730446Z","shell.execute_reply":"2024-08-06T20:54:01.604756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The application of deep learning methods is a challenging task from understanding the dataset to preparing and modelling it. In this notebook, the stages of this challenging tasks were carried out using the Breast Histopathology Images dataset. The dataset was first visualized and positive and negative patches were categorized. Subsequently, the under-sampling method was used to solve the imbalanced class problem. Finally, a complicated model was built based on the CNN method, the training of the model was completed and the model was tested. Although the results obtained are successful, different results may be obtained in the future with different deep learning models or hybrid models, different parameter values, different epoch numbers for the same dataset. ","metadata":{}}]}